{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Datasets for Faro Unit Testing\n",
    "\n",
    "This notebook steps through the process of extracting a small set of data to use for `faro` unit testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which version of the Stack am I using?\n",
    "!eups list -s | grep lsst_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import gzip\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import lsst.daf.butler as dafButler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shrink_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries\n",
    "\n",
    "Use the ci_hsc_gen3\n",
    "\n",
    "(1) Set up [testdata_ci_hsc](https://github.com/lsst/testdata_ci_hsc) following README instructions.\n",
    "\n",
    "(2) Set up [ci_hsc_gen3](https://github.com/lsst/ci_hsc_gen3) following README instructions.\n",
    "\n",
    "(3) Run `faro`. First, set up the package.\n",
    "\n",
    "```\n",
    "cd repos/metric-pipeline-tasks\n",
    "setup -k -r .\n",
    "```\n",
    "\n",
    "We will consider a subset of detectors and single patch to keep file sizes small. Note that the full tract will only be partially populated for metrics that use a full tract. Note that one cannot choose a subset of detectors much smaller than this because the repeatability metrics require a minimum number of matched observations.\n",
    "\n",
    "Run the single-band matched catalogs and metrics:\n",
    "\n",
    "```\n",
    "pipetask run -j 12 -b \"$CI_HSC_GEN3_DIR\"/DATA/butler.yaml --register-dataset-types -p pipelines/metrics_pipeline_matched.yaml -d \"tract=0 AND patch=70 AND detector IN (4,16,17,23,24) AND skymap='discrete/ci_hsc' AND instrument='HSC'\" --output kbechtol/matched_small -i HSC/runs/ci_hsc\n",
    "```\n",
    "\n",
    "Run the multi-band matched catalogs and metrics:\n",
    "\n",
    "```\n",
    "pipetask run -j 12 -b \"$CI_HSC_GEN3_DIR\"/DATA/butler.yaml --register-dataset-types -p pipelines/metrics_pipeline_matched_multi.yaml -d \"tract=0 AND patch=70 AND detector IN (4,16,17,23,24) AND skymap='discrete/ci_hsc' AND instrument='HSC'\" --output kbechtol/matched_multi_small -i HSC/runs/ci_hsc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore repo contents and prepare to extract datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a local version of ci_hsc_gen3\n",
    "repo = '/home/kbechtol/DATA/ci_hsc_gen3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for staging the test datasets\n",
    "staging_dir = '/home/kbechtol/repos/metric-pipeline-tasks/tests/data_staging/'\n",
    "if not os.path.exists(staging_dir):\n",
    "    print('Creating %s ...'%(staging_dir))\n",
    "    os.makedirs(staging_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = os.path.join(repo, 'DATA', 'butler.yaml')\n",
    "try: butler = dafButler.Butler(config=config)\n",
    "except ValueError as e: print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "registry = butler.registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in registry.queryCollections():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in registry.queryDatasetTypes(): \n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collections = 'kbechtol/matched_one_patch'\n",
    "collections = 'kbechtol/matched_small'\n",
    "skymap_ref = list(registry.queryDatasets('skyMap', collections=collections, findFirst=True))[0]#.dataId['skymap']\n",
    "print(skymap_ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of how one could explore the file tree in the data repo. Provided only for informational purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/kbechtol/DATA/ci_hsc_gen3/DATA/kbechtol/matched/20210127T041304Z'\n",
    "yaml_files = glob.glob(path + \"/**/*.yaml\", recursive = True)\n",
    "for file in yaml_files:\n",
    "    if 'metadata' in file:\n",
    "        continue\n",
    "    new_name = file.replace('_discrete_ci_hsc_kbechtol_matched_20210127T041304Z', '')\n",
    "    print(os.path.basename(new_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Measurements\n",
    "\n",
    "Access the `.yaml` containing metric results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMeasurementFilenames(butler, collections, tract):\n",
    "    registry = butler.registry\n",
    "    skymap_name = list(registry.queryDatasets('skyMap', collections=collections, findFirst=True))[0].dataId['skymap']\n",
    "    paths = []\n",
    "    outfiles = []\n",
    "    for x in registry.queryDatasetTypes(): \n",
    "        if x.storageClass.name == 'MetricValue':\n",
    "            dataid = {'tract': tract, 'skymap': skymap_name}\n",
    "            refs = list(registry.queryDatasets(x.name, dataId=dataid, collections=collections))\n",
    "            if len(refs) == 0:\n",
    "                continue\n",
    "            for ii in range(0, len(refs)):\n",
    "                measurement = butler.get(refs[ii], collections=collections)\n",
    "                uri = butler.getURI(x.name, refs[ii].dataId, collections=collections)\n",
    "                outfile = '%s%s%s%s'%(measurement.metric_name, \n",
    "                                      '_expected',\n",
    "                                      os.path.basename(uri.path).split('_discrete')[0].split('HSC')[1],\n",
    "                                      os.path.splitext(uri.path)[1])\n",
    "                paths.append(uri.path)\n",
    "                outfiles.append(outfile)\n",
    "            \n",
    "    return list(zip(paths, outfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = 'kbechtol/matched_small'\n",
    "metric_results_single_band = getMeasurementFilenames(butler, collections, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_single_band[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for infile, outfile_base in np.unique(metric_results_single_band, axis=0):\n",
    "    outfile = os.path.join(staging_dir, outfile_base)\n",
    "    shutil.copyfile(infile, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = 'kbechtol/matched_multi_small'\n",
    "metric_results_multi_band = getMeasurementFilenames(butler, collections, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_results_multi_band[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for infile, outfile_base in np.unique(metric_results_multi_band, axis=0):\n",
    "    outfile = os.path.join(staging_dir, outfile_base)\n",
    "    shutil.copyfile(infile, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Matched Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(filename):\n",
    "    with open(filename, 'rb') as f_in:\n",
    "        with gzip.open(filename + '.gz', 'wb') as f_out:\n",
    "            shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatchedCatalogFilenames(butler, collections, datasettype, tract):\n",
    "    registry = butler.registry\n",
    "    skymap_name = list(registry.queryDatasets('skyMap', collections=collections, findFirst=True))[0].dataId['skymap']\n",
    "    dataid = {'tract': tract, 'skymap': skymap_name}\n",
    "    refs = list(registry.queryDatasets(datasettype, \n",
    "                                       dataId=dataid, \n",
    "                                       collections=collections))\n",
    "    paths = []\n",
    "    outfiles = []\n",
    "    for ii in range(0, len(refs)):\n",
    "        uri = butler.getURI(datasettype, refs[ii].dataId, collections=collections)\n",
    "        outfile = datasettype + os.path.basename(uri.path).split('_discrete')[0].split('HSC')[1] + os.path.splitext(uri.path)[1]\n",
    "        paths.append(uri.path)\n",
    "        outfiles.append(outfile)\n",
    "        \n",
    "    #return (uri.path, outfile)\n",
    "    return list(zip(paths, outfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = 'kbechtol/matched_small'\n",
    "matched_catalog_single_band = getMatchedCatalogFilenames(butler, collections, 'matchedCatalogTract', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_catalog_single_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for infile, outfile_base in np.unique(matched_catalog_single_band, axis=0):\n",
    "    outfile = os.path.join(staging_dir, outfile_base)\n",
    "    shrink_cat.shrinkCat(infile, outfile)\n",
    "    compress(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = 'kbechtol/matched_multi_small'\n",
    "matched_catalog_multi_band = getMatchedCatalogFilenames(butler, collections, 'matchedCatalogMulti', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matched_catalog_multi_band)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for infile, outfile_base in np.unique(matched_catalog_multi_band, axis=0):\n",
    "    outfile = os.path.join(staging_dir, outfile_base)\n",
    "    shrink_cat.shrinkCat(infile, outfile)\n",
    "    compress(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that we can load the compressed file\n",
    "print(outfile + '.gz')\n",
    "from lsst.afw.table import SimpleCatalog\n",
    "catalog = SimpleCatalog.readFits(outfile + '.gz')\n",
    "#catalog['detect_isPrimary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Matched Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = 'kbechtol/matched'\n",
    "#collections = 'kbechtol/matched_small'\n",
    "#collections = 'kbechtol/matched_multi_small'\n",
    "skymap_ref = list(registry.queryDatasets('skyMap', collections=collections, findFirst=True))[0]\n",
    "skymap = butler.get(skymap_ref, collections=collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataid = {'tract': 0, 'skymap': skymap_ref.dataId['skymap'], 'band': 'r'}\n",
    "refs = list(registry.queryDatasets('matchedCatalogTract', dataId=dataid, collections=collections))\n",
    "#refs = list(registry.queryDatasets('matchedCatalogMulti', dataId=dataid, collections=collections))\n",
    "print(len(refs))\n",
    "matched_catalog = butler.get(refs[0], collections=collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(matched_catalog)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_catalog.schema.getNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tract_dict = {}\n",
    "tract_id_array = []\n",
    "patch_id_array = []\n",
    "for record in matched_catalog:\n",
    "    coord = record.getCoord()\n",
    "    tract_id = skymap.findTract(coord).getId()\n",
    "    if str(tract_id) not in tract_dict.keys():\n",
    "        tract_dict[str(tract_id)] = skymap.generateTract(tract_id)\n",
    "    patch_id = tract_dict[str(tract_id)].getSequentialPatchIndex(tract_dict[str(tract_id)].findPatch(coord))\n",
    "    tract_id_array.append(tract_id)\n",
    "    patch_id_array.append(patch_id)\n",
    "    \n",
    "tract_id_array = np.array(tract_id_array)\n",
    "patch_id_array = np.array(patch_id_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "for patch_index in np.unique(patch_id_array):\n",
    "    selection = (patch_id_array ==  patch_index)\n",
    "    if patch_index == 70:\n",
    "        marker = 's'\n",
    "    else:\n",
    "        marker = 'o'\n",
    "    plt.scatter(np.degrees(matched_catalog['coord_ra'][selection]), \n",
    "                np.degrees(matched_catalog['coord_dec'][selection]),\n",
    "                #c=patch_id_array,\n",
    "                edgecolor='none', s=5, marker=marker)\n",
    "    print(patch_index, np.sum(selection))\n",
    "plt.xlabel('coord_ra (deg)')\n",
    "plt.ylabel('coord_dec (deg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.isfinite(matched_catalog['coord_dec']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find subset of visit and detector combinations\n",
    "\n",
    "In order to decrease the size of files persisted in the repo, and retain consistency with the end-to-end running of `faro` pipeline, we can select a subset of visits and/or detectors to pass as input to `pipetask` when running `faro`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = list(registry.queryDatasets('calexp', collections=collections))\n",
    "#refs = list(registry.queryDatasets('calexp', where=\"detector in (4,16,17,23,24) and instrument = 'HSC'\", collections=collections))\n",
    "ra = []\n",
    "dec = []\n",
    "band = []\n",
    "visit = []\n",
    "detector = []\n",
    "for ref in refs:\n",
    "    # There must be a faster way to get the approximate centers of each detector\n",
    "    calexp = butler.get(ref, collections=collections)\n",
    "    ra.append(calexp.getWcs().getSkyOrigin().getRa().asDegrees())\n",
    "    dec.append(calexp.getWcs().getSkyOrigin().getDec().asDegrees())\n",
    "    band.append(ref.dataId['band'])\n",
    "    visit.append(ref.dataId['visit'])\n",
    "    detector.append(ref.dataId['detector'])\n",
    "    \n",
    "ra = np.array(ra)\n",
    "dec = np.array(dec)\n",
    "band = np.array(band)\n",
    "visit = np.array(visit)\n",
    "detector = np.array(detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the individual visits and detectors\n",
    "plt.figure()\n",
    "plt.scatter(ra[band=='r'], dec[band=='r'], marker='x')\n",
    "plt.scatter(ra[band=='i'], dec[band=='i'], marker='+')\n",
    "for ii in range(0, len(visit)):\n",
    "    plt.text(ra[ii], dec[ii], '(%s,%s)'%(visit[ii], detector[ii]))\n",
    "plt.xlabel('coord_ra (deg)')\n",
    "plt.ylabel('coord_dec (deg)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the dimensions of an individual detector?\n",
    "calexp = butler.get(ref, collections=collections)\n",
    "print(calexp.getBBox().getWidth() * calexp.getWcs().getPixelScale().asDegrees())\n",
    "print(calexp.getBBox().getHeight() * calexp.getWcs().getPixelScale().asDegrees())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.unique(matched_catalog['detector'][patch_id_array == 70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection = (patch_id_array == 70)\n",
    "#np.unique(list(zip(matched_catalog['visit'][selection], \n",
    "#                   matched_catalog['detector'][selection])), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying over the files needed from staging area\n",
    "\n",
    "```\n",
    "cp tests/data_staging/matchedCatalog*.fits.gz tests/data/.\n",
    "cp tests/data_staging/TE*.yaml tests/data/.\n",
    "cp tests/data_staging/A*1*.yaml tests/data/.\n",
    "cp tests/data_staging/P*1*.yaml tests/data/.\n",
    "cp tests/data_staging/PA2*.yaml tests/data/.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Single-Visit Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = 'HSC/runs/ci_hsc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_refs = list(registry.queryDatasets('src', collections=collections, detector=100, instrument='HSC',\n",
    "                                       where='visit=903986'))\n",
    "assert len(src_refs) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = butler.getURI(src_refs[0], collections=collections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = uri.path\n",
    "outifle = os.path.join(staging_dir, uri.basename())\n",
    "print(infile)\n",
    "print(outfile)\n",
    "shutil.copyfile(infile, outfile)\n",
    "compress(outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSST",
   "language": "python",
   "name": "lsst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
